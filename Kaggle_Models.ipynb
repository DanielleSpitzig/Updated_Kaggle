{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "die2wtf-7u14"
      },
      "source": [
        "# Load in necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import sklearn\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPQ0HiZ58ZpL"
      },
      "source": [
        "random.seed(20602629)\n",
        "#----- Classification Models -----\n",
        "##Helper functions Base Models##\n",
        "#Logistic regression returns AUC score\n",
        "def log_reg(train, test, y_train, y_test, reg='l1', opt = \"saga\"):\n",
        "    #If using elasticnet need a l1 ratio - setting to 0.5\n",
        "    if reg == \"elasticnet\":\n",
        "        logisticRegr = LogisticRegression(penalty = reg, solver = opt, max_iter = 100, l1_ratio = 0.5)\n",
        "    else:\n",
        "        logisticRegr = LogisticRegression(penalty = reg, solver = opt, max_iter = 100)\n",
        "    logisticRegr.fit(train, y_train)\n",
        "    prob_y = logisticRegr.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "\n",
        "#SVM function returns AUC score\n",
        "def linSVM(train, test, y_train, y_test, kern = 'rbf'):\n",
        "    classifier = SVC(kernel = kern, probability = True, max_iter=100)\n",
        "    classifier.fit(train, y_train)\n",
        "    prob_y = classifier.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "\n",
        "#Naive Bayes\n",
        "def nbayes(train, test, y_train, y_test, laplace = 1e-9):\n",
        "    classifier = GaussianNB(var_smoothing = laplace)\n",
        "    classifier.fit(train, y_train)\n",
        "    prob_y = classifier.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "\n",
        "#KNN\n",
        "def knn(train, test, y_train, y_test, num_n = 10):\n",
        "    classifier = KNeighborsClassifier(n_neighbors=num_n)\n",
        "    classifier.fit(train, y_train)\n",
        "    prob_y = classifier.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "\n",
        "#Decision Trees\n",
        "def dtree(train, test, y_train, y_test, depth = 5):\n",
        "    classifier = DecisionTreeClassifier(max_depth = depth)\n",
        "    classifier.fit(train, y_train)\n",
        "    prob_y = classifier.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "  \n",
        "## Helper functions for base model comparison##\n",
        "#Run each model with dif parameters on input data - return best validated AUC and index\n",
        "def comp_LR(X_train, X_test, y_train, y_test):\n",
        "    #Logistic regression with L1, L2, and elasticnet\n",
        "    AUC_LR = []\n",
        "    AUC_LR.append(log_reg(X_train, X_test, y_train, y_test))\n",
        "    AUC_LR.append(log_reg(X_train, X_test, y_train, y_test, reg=\"l2\"))\n",
        "    AUC_LR.append(log_reg(X_train, X_test, y_train, y_test, reg=\"elasticnet\"))\n",
        "    #L1 can use liblinear or saga\n",
        "    AUC_LR.append(log_reg(X_train, X_test, y_train, y_test, opt=\"liblinear\"))\n",
        "    #Get max and position of max to find best logistic regression model\n",
        "    best = np.max(AUC_LR)\n",
        "    best_index = np.argmax(AUC_LR)\n",
        "    print(\"Best LR model Index: {}, AUC: {}\".format(best_index, best))\n",
        "\n",
        "def comp_SVM(X_train, X_test, y_train, y_test):\n",
        "    #SVM with different kernels\n",
        "    AUC_SVM = []\n",
        "    AUC_SVM.append(linSVM(X_train, X_test, y_train, y_test, kern=\"linear\"))\n",
        "    AUC_SVM.append(linSVM(X_train, X_test, y_train, y_test))\n",
        "    AUC_SVM.append(linSVM(X_train, X_test, y_train, y_test, kern=\"poly\"))\n",
        "    AUC_SVM.append(linSVM(X_train, X_test, y_train, y_test, kern=\"sigmoid\"))\n",
        "    #Get max and position of max to find best model\n",
        "    best = np.max(AUC_SVM)\n",
        "    best_index = np.argmax(AUC_SVM)\n",
        "    print(\"Best SVM model Index: {}, AUC: {}\".format(best_index, best))\n",
        "\n",
        "def comp_NB(X_train, X_test, y_train, y_test):\n",
        "    #Naive Bayes with different smoothing parameters\n",
        "    AUC_NB = []\n",
        "    AUC_NB.append(nbayes(X_train, X_test, y_train, y_test))\n",
        "    AUC_NB.append(nbayes(X_train, X_test, y_train, y_test, laplace=1e-5))\n",
        "    AUC_NB.append(nbayes(X_train, X_test, y_train, y_test, laplace=1e-1))\n",
        "    AUC_NB.append(nbayes(X_train, X_test, y_train, y_test, laplace=1))\n",
        "    #Get max and position of max to find best model\n",
        "    best = np.max(AUC_NB)\n",
        "    best_index = np.argmax(AUC_NB)\n",
        "    print(\"Best NB model Index: {}, AUC: {}\".format(best_index, best))\n",
        "\n",
        "def comp_KNN(X_train, X_test, y_train, y_test):\n",
        "    #KNN with different num of neighbours\n",
        "    AUC_KNN = []\n",
        "    AUC_KNN.append(knn(X_train, X_test, y_train, y_test, num_n=5))\n",
        "    AUC_KNN.append(knn(X_train, X_test, y_train, y_test, num_n=10))\n",
        "    AUC_KNN.append(knn(X_train, X_test, y_train, y_test, num_n=15))\n",
        "    AUC_KNN.append(knn(X_train, X_test, y_train, y_test, num_n=20))\n",
        "    #Get max and position of max to find best model\n",
        "    best = np.max(AUC_KNN)\n",
        "    best_index = np.argmax(AUC_KNN)\n",
        "    print(\"Best KNN model Index: {}, AUC: {}\".format(best_index, best))\n",
        "\n",
        "def comp_dtree(X_train, X_test, y_train, y_test):\n",
        "    #Decision trees with different depths\n",
        "    AUC_DT = []\n",
        "    AUC_DT.append(dtree(X_train, X_test, y_train, y_test))\n",
        "    AUC_DT.append(dtree(X_train, X_test, y_train, y_test, depth=10))\n",
        "    AUC_DT.append(dtree(X_train, X_test, y_train, y_test, depth=15))\n",
        "    AUC_DT.append(dtree(X_train, X_test, y_train, y_test, depth=20))\n",
        "    #Get max and position of max to find best model\n",
        "    best = np.max(AUC_DT)\n",
        "    best_index = np.argmax(AUC_DT)\n",
        "    print(\"Best DTree model Index: {}, AUC: {}\".format(best_index, best))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8AAIe-N8fjK"
      },
      "source": [
        "## Helper functions for Ensemble ##\n",
        "#Random forest with num estimators and depth\n",
        "def rforest(train, test, y_train, y_test, n_est = 500, depth=5):\n",
        "    classifier = RandomForestClassifier(n_estimators = n_est, max_depth=depth)\n",
        "    classifier.fit(train, y_train)\n",
        "    prob_y = classifier.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "#Adaboost with default decision trees and max_depth 1\n",
        "def ada(train, test, y_train, y_test, n_est = 100):\n",
        "    ada_class = AdaBoostClassifier(n_estimators=n_est)\n",
        "    ada_class.fit(train, y_train)\n",
        "    prob_y = ada_class.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    return roc_auc_score(y_test, pred_y)\n",
        "#Stacking method with LR used to aggregrate final predictions\n",
        "def stack(train, test, y_train, y_test, ests = 0):\n",
        "    if ests == 0:\n",
        "        ests = [('rf', RandomForestClassifier(n_estimators=100, max_depth = 10)),\n",
        "        ('ada', AdaBoostClassifier(n_estimators=100)), \n",
        "        ('lg', LogisticRegression(solver='liblinear'))]\n",
        "    stack_class = StackingClassifier(estimators = ests)\n",
        "    stack_class.fit(train, y_train)\n",
        "    prob_y = stack_class.predict_proba(test)\n",
        "    pred_y = prob_y[:,1]\n",
        "    print(\"AUC of stacked: {}\".format(roc_auc_score(y_test, pred_y)))\n",
        "\n",
        "#Random Forest tuning\n",
        "def comp_rf(X_train, X_test, y_train, y_test):\n",
        "    #RF with different number of estimators - 10-200 and depth\n",
        "    num_ests = list(range(10, 201, 10))\n",
        "    depths = list(range(1, 10, 1))\n",
        "    max_AUC = 0\n",
        "    for ii in num_ests:\n",
        "        for dep in depths:\n",
        "            rf_AUC = rforest(X_train, X_test, y_train, y_test, n_est=ii, depth=dep)\n",
        "            if rf_AUC > max_AUC:\n",
        "                max_AUC = rf_AUC\n",
        "                (depth, est) = (dep, ii)\n",
        "    print(\"Best RF Num_Est: {}, depth:{},  AUC: {}\".format(est, dep, max_AUC))\n",
        "\n",
        "#Adaboost tuning\n",
        "def comp_ada(X_train, X_test, y_train, y_test):\n",
        "    #Adaboost with different number of estimators - 10-200\n",
        "    max_AUC = 0\n",
        "    max_i = 0\n",
        "    num_ests = list(range(10, 201, 10))\n",
        "    for ii in num_ests:\n",
        "        ada_AUC = ada(X_train, X_test, y_train, y_test, n_est=ii)\n",
        "        if ada_AUC > max_AUC:\n",
        "            max_AUC = ada_AUC\n",
        "            max_i = ii\n",
        "    print(\"Best Adaboost Num_Est: {}, AUC: {}\".format(num_ests.index(max_i), max_AUC))\n",
        "\n",
        "\n",
        "#Run simple one layer with different optimization functions to find best\n",
        "def NN_norm_opt(train, test, y_train, y_test, hidden = 10):\n",
        "    opts = [\"sgd\", \"adam\", \"adadelta\", \"rmsprop\"]\n",
        "    best = 0\n",
        "    (_,dim) = train.shape\n",
        "    for opt in opts:\n",
        "        model = Sequential()\n",
        "        model.add(Dense(hidden, input_dim=dim, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        #Compile model and fit it\n",
        "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        model.fit(train, y_train, epochs=5, verbose=0, validation_split=0.2, shuffle=True)\n",
        "        pred_y = model.predict(test)\n",
        "        NN_AUC = roc_auc_score(y_test, pred_y)\n",
        "        if best < NN_AUC:\n",
        "            best=NN_AUC\n",
        "            best_opt=opt\n",
        "    #At end return best AUC and best opts\n",
        "    return(best, best_opt)\n",
        "\n",
        "#Functions for 2 and 3 layer NN\n",
        "def layer2(train, test, n=50, opt=\"sgd\", epoch=50, batch=100):\n",
        "    # create model\n",
        "    (_,dim) = train.shape\n",
        "    model = Sequential()\n",
        "    model.add(Dense(n, input_dim=dim, activation='relu'))\n",
        "    model.add(Dense(n, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    #Fit model and run cross-validation\n",
        "    model.fit(train, test, epochs = epoch, verbose = 0, validation_split = 0.2, shuffle = True, batch_size = batch)\n",
        "    return model\n",
        "\n",
        "def layer3(train, test, n=50, opt=\"sgd\", epoch=50, batch=100):\n",
        "    # create model\n",
        "    (_,dim) = train.shape\n",
        "    model = Sequential()\n",
        "    model.add(Dense(n, input_dim=dim, activation='relu'))\n",
        "    model.add(Dense(n, activation='relu'))\n",
        "    model.add(Dense(n, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    #Fit model and run cross-validation\n",
        "    model.fit(train, test, epochs = epoch, verbose = 0, validation_split = 0.2, shuffle = True, batch_size = batch)\n",
        "    return model\n",
        "\n",
        "#NN using above functions with built-in grid search for batch and num neurons\n",
        "def NN_valid(train, test, y_train, y_test, opt=\"sgd\"):\n",
        "    #Check 30 - 150 for num neurons by layer and batches 10 - 25\n",
        "    num_neur = list(range(30, 180, 30))\n",
        "    batches = [10, 15, 20, 25]\n",
        "    best_2 = 0\n",
        "    best_3 = 0\n",
        "    for batch in batches:\n",
        "        for n in num_neur:\n",
        "            #Using batch and neurons get 2 and 3 layer\n",
        "            model1 = layer2(train, y_train, n=n, batch=batch, opt=opt)\n",
        "            model2 = layer3(train, y_train, n=n, batch=batch, opt=opt)\n",
        "            pred_2 = model1.predict(test, batch_size = batch)\n",
        "            pred_3 = model2.predict(test, batch_size = batch)\n",
        "            lay2_AUC = roc_auc_score(y_test, pred_2)\n",
        "            lay3_AUC = roc_auc_score(y_test, pred_3)\n",
        "            #Update best for each layer with the neuron and batch\n",
        "            if lay2_AUC > best_2:\n",
        "                best_2 = lay2_AUC\n",
        "                (neur_2, batch_2) = (n, batch)\n",
        "            if lay3_AUC > best_3:\n",
        "                best_3 = lay3_AUC\n",
        "                (neur_3, batch_3) = (n, batch)\n",
        "    #At end check which best is better and return\n",
        "    if best_2 >= best_3:\n",
        "      print(\"Best NN Batch: {}, Neurons: {}, Layers: {}, AUC: {}\".format(batch_2, neur_2, \"2\", best_2))\n",
        "    else:\n",
        "      print(\"Best NN Batch: {}, Neurons: {}, Layers: {}, AUC: {}\".format(batch_3, neur_3, \"3\", best_3))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b11MQOA38-Sc",
        "outputId": "fc601af4-9ae8-41f1-ea77-23028909998b"
      },
      "source": [
        "## Read in data and get train test splits##\n",
        "train = pd.read_csv('cleaned_train.csv')\n",
        "test = pd.read_csv('cleaned_test.csv')\n",
        "train_labels = pd.read_csv('Train_Label.csv')\n",
        "test_id = pd.read_csv('test.csv')\n",
        "\n",
        "train.drop('Unnamed: 0', axis = 1, inplace=True)\n",
        "test.drop('Unnamed: 0', axis = 1, inplace=True)\n",
        "train_labels.drop('Unnamed: 0', axis = 1, inplace=True)\n",
        "test_id.drop('Unnamed: 0', axis = 1, inplace=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3,6,10,12,21,24,35,85,87,88,89,100,124,126,127,128,130,131,133,166,172,177,193,194,195,205,206,207,220,222,228,229,230,240,257,258,260,261,262) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsTRZM0CWkSY",
        "outputId": "4455b749-c38d-4064-8e87-bc701e671c69"
      },
      "source": [
        "test_id"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       14061\n",
              "1       16467\n",
              "2       25725\n",
              "3        9100\n",
              "4       32597\n",
              "        ...  \n",
              "9240    31430\n",
              "9241     3876\n",
              "9242    20710\n",
              "9243    26015\n",
              "9244    12970\n",
              "Name: id, Length: 9245, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEuqa2L5AG6j"
      },
      "source": [
        "col_names = list(train.columns)\n",
        "\n",
        "#Apply normalization before split so it carries through\n",
        "mm_scaler = MinMaxScaler()\n",
        "train_mm = mm_scaler.fit_transform(train)\n",
        "train = pd.DataFrame(train_mm, columns=col_names)\n",
        "\n",
        "test_mm = mm_scaler.fit_transform(test)\n",
        "test = pd.DataFrame(test_mm, columns=col_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, train_labels, test_size=0.33)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxGD4-uC8iI3"
      },
      "source": [
        "## Run base models on full data ##\n",
        "# comp_LR(X_train, X_test, y_train.values.ravel(), y_test.values.ravel())\n",
        "# comp_SVM(X_train, X_test, y_train.values.ravel(), y_test.values.ravel())\n",
        "# comp_NB(X_train, X_test, y_train.values.ravel(), y_test.values.ravel())\n",
        "# comp_KNN(X_train, X_test, y_train.values.ravel(), y_test.values.ravel())\n",
        "# comp_dtree(X_train, X_test, y_train.values.ravel(), y_test.values.ravel())\n",
        "\n",
        "#Best is LR with validated AUC of ~0.876 - takes a REALLY long time\n",
        "\n",
        "#Since data so large won't run more complex models on it"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDB9l5nF8nG2"
      },
      "source": [
        "## Reducing dimensions - used random forest to get variable importance ##\n",
        "#Don't use above split here - not prediction just for importance over all vars\n",
        "clf = RandomForestClassifier(n_estimators = 1000, max_depth=10, random_state=0)\n",
        "clf.fit(train, train_labels.values.ravel())\n",
        "\n",
        "feature_importances = list(clf.feature_importances_)\n",
        "columns = list(train.columns)\n",
        "\n",
        "## Change n to modify how many features\n",
        "#Found 100 was good with trade-off of complexity and accuracy\n",
        "n = 100 #200, 300 overfit, 50 underfit, 100, 150 similar\n",
        "top_n_idx = np.argsort(feature_importances)[-n:]\n",
        "top_n_values = [feature_importances[i] for i in top_n_idx]\n",
        "\n",
        "important_features = []\n",
        "for i in list(top_n_idx):\n",
        "    important_features.append(columns[i])\n",
        "\n",
        "#Use above row splits and subset at columns\n",
        "rf_train = X_train[important_features]\n",
        "rf_test = X_test[important_features]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz19mALXCfhU",
        "outputId": "acbf3d80-7a4e-487c-9d86-ceb1d88b8067"
      },
      "source": [
        "## Use reduced dataset on models ##\n",
        "# Run base models - will print results automatically\n",
        "comp_LR(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best LR model Index: 0, AUC: 0.8836045836852348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm9p-6dJfxUB",
        "outputId": "f7c86bf3-64c2-44b5-b397-1514198c67bf"
      },
      "source": [
        "comp_SVM(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best SVM model Index: 0, AUC: 0.711165067292274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r498PFOfzCW",
        "outputId": "10f4d8eb-f6ca-4f44-ca3f-1790342cbbdf"
      },
      "source": [
        "comp_NB(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best NB model Index: 0, AUC: 0.7894145079022004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Y-150Hf0xA",
        "outputId": "345e16b3-232d-4971-8a53-dee6a0c46f9a"
      },
      "source": [
        "comp_KNN(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best KNN model Index: 3, AUC: 0.7974828646008106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW4pt9t5f2qu",
        "outputId": "17c0fae7-1cab-4335-ed0a-78afd9eeeec0"
      },
      "source": [
        "comp_dtree(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best DTree model Index: 0, AUC: 0.8777921835893869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRjaSdvRZWQU",
        "outputId": "dd3249fb-c6a5-4458-d7ca-b6001c9ac6d4"
      },
      "source": [
        "#Now let's run on some ensemble methods\n",
        "comp_rf(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best RF Num_Est: 200, depth:9,  AUC: 0.8861452663594408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM8YfA9Gjg1y",
        "outputId": "02b4fbd8-d991-429f-af44-b91fa5359bbc"
      },
      "source": [
        "comp_ada(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Adaboost Num_Est: 17, AUC: 0.8887039184665846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLGf9mgWj9fR",
        "outputId": "43f061ba-800f-4e59-807b-fd71dbbe336e"
      },
      "source": [
        "NN_norm_opt(rf_train, rf_test, y_train, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.865860276844727, 'rmsprop')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf_1O2hcmiN8",
        "outputId": "bf920a84-122e-47da-f10d-b5c37ed66c61"
      },
      "source": [
        "NN_valid(rf_train, rf_test, y_train, y_test, opt=\"rmsprop\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best NN Batch: 25, Neurons: 30, Layers: 2, AUC: 0.8685987985148234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRzo9giT3Mi_"
      },
      "source": [
        "## PCA to reduce dimenstions then run same models ##\n",
        "pca = PCA(0.75, svd_solver=\"full\")\n",
        "#Want to use scaled data here\n",
        "pca.fit(train)\n",
        "p_train = pca.transform(train)\n",
        "p_test = pca.transform(test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO7jO6oe8yf1"
      },
      "source": [
        "pca_train, pca_test, ytrain, ytest = train_test_split(p_train, train_labels, test_size=0.33)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scUory-l81-T",
        "outputId": "2da7f167-3fd5-4eac-f621-c2c161424489"
      },
      "source": [
        "## Use reduced PCA dataset on models ##\n",
        "# Run base models - will print results automatically\n",
        "comp_LR(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best LR model Index: 3, AUC: 0.8190707661172979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy61Qz8Z89Tw",
        "outputId": "aaaa9236-1a51-423a-959b-e984519dca09"
      },
      "source": [
        "comp_SVM(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best SVM model Index: 1, AUC: 0.6346257676471458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFcXJYld8_Ay",
        "outputId": "9161c89b-6264-492e-b141-4c50c5d9391e"
      },
      "source": [
        "comp_NB(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best NB model Index: 2, AUC: 0.7886630868332601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fRNhXKB9JTp",
        "outputId": "ed5490b3-e875-484b-8e5d-4453ccea54ee"
      },
      "source": [
        "comp_KNN(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best KNN model Index: 3, AUC: 0.7345969021310246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWffSKmD9Q71",
        "outputId": "592c93db-35ab-449f-c471-95991324199d"
      },
      "source": [
        "comp_dtree(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best DTree model Index: 0, AUC: 0.70259054391379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpT1oO559Su6",
        "outputId": "a177c96b-e952-4e5b-bac2-9fd890ca2891"
      },
      "source": [
        "#Now let's run on some ensemble methods\n",
        "comp_rf(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best RF Num_Est: 190, depth:9,  AUC: 0.7806430498893013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LVIs1v69Zfi",
        "outputId": "d4124fa2-188a-47c3-af8b-e4bb011b56a9"
      },
      "source": [
        "comp_ada(pca_train, pca_test, ytrain.values.ravel(), ytest.values.ravel())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Adaboost Num_Est: 17, AUC: 0.7925930158944863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27uGxaO49ggA",
        "outputId": "faf49167-4385-47ea-c171-631803ff58d6"
      },
      "source": [
        "#Tune NN and run\n",
        "NN_norm_opt(pca_train, pca_test, ytrain, ytest) #Best was rmsprop"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8172319408844636, 'rmsprop')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Wj-UmjUAoA",
        "outputId": "0278beaa-795f-40e4-bd13-0ec35db58635"
      },
      "source": [
        "NN_valid(pca_train, pca_test, ytrain, ytest, opt=\"rmsprop\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best NN Batch: 20, Neurons: 30, Layers: 2, AUC: 0.7623890047339121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQOdfMhc5MD"
      },
      "source": [
        "#Do two stacked models with subset data - one with two best models and one with three best models\n",
        "est_3 = [('rf', RandomForestClassifier(n_estimators=200, max_depth = 9)),\n",
        "         ('ada', AdaBoostClassifier(n_estimators=17)), \n",
        "         ('lg', LogisticRegression(solver='saga', penalty=\"l1\", max_iter=100))]\n",
        "est_2 = [('rf', RandomForestClassifier(n_estimators=100, max_depth = 10)),\n",
        "         ('ada', AdaBoostClassifier(n_estimators=100))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYBLP2TBysH-",
        "outputId": "fcc3e612-0842-48ea-fbca-5726f446c133"
      },
      "source": [
        "stack(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel(), ests=est_3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC of stacked: 0.8902899445248642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEYzIKvzy4_U",
        "outputId": "a26ca23f-4fed-4b01-f326-083db71eb0ff"
      },
      "source": [
        "stack(rf_train, rf_test, y_train.values.ravel(), y_test.values.ravel(), ests=est_2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC of stacked: 0.8861130270826999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4LZhcQNTMpI",
        "outputId": "94fa739c-d0d1-4176-a0b9-41d454e6a822"
      },
      "source": [
        "## Use top 2 best models to get probability of classification to submit ##\n",
        "#Want probability because using AUC to compute\n",
        "#Stacked with reduced variable importance\n",
        "top1 = StackingClassifier(estimators = est_3)\n",
        "top1.fit(train[important_features], train_labels.values.ravel())\n",
        "prob_top1 = top1.predict_proba(test[important_features])\n",
        "pred_top1 = prob_top1[:,1]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdIz_drGXYKa"
      },
      "source": [
        "pred_top1 = pd.DataFrame(pred_top1)\n",
        "pred_top1['id'] = test_id\n",
        "pred_top1.to_csv(\"top_prediction.csv\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRrzvL2ST4Y6"
      },
      "source": [
        "top2 =  AdaBoostClassifier(n_estimators=17)\n",
        "top2.fit(train[important_features], train_labels.values.ravel())\n",
        "prob_top2 = top2.predict_proba(test[important_features])\n",
        "pred_top2 = prob_top2[:,1]\n",
        "pred_top2 = pd.DataFrame(pred_top2)\n",
        "pred_top2['id'] = test_id\n",
        "pred_top2.to_csv(\"top2_prediction.csv\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "zFQFP66mYK37",
        "outputId": "2b6e1877-51a0-40cc-81bb-1a987639daa7"
      },
      "source": [
        "pred_top1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.094222</td>\n",
              "      <td>14061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.192832</td>\n",
              "      <td>16467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.804983</td>\n",
              "      <td>25725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.613568</td>\n",
              "      <td>9100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.505400</td>\n",
              "      <td>32597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9240</th>\n",
              "      <td>0.868917</td>\n",
              "      <td>31430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9241</th>\n",
              "      <td>0.437476</td>\n",
              "      <td>3876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9242</th>\n",
              "      <td>0.839335</td>\n",
              "      <td>20710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9243</th>\n",
              "      <td>0.724148</td>\n",
              "      <td>26015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9244</th>\n",
              "      <td>0.119712</td>\n",
              "      <td>12970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9245 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0     id\n",
              "0     0.094222  14061\n",
              "1     0.192832  16467\n",
              "2     0.804983  25725\n",
              "3     0.613568   9100\n",
              "4     0.505400  32597\n",
              "...        ...    ...\n",
              "9240  0.868917  31430\n",
              "9241  0.437476   3876\n",
              "9242  0.839335  20710\n",
              "9243  0.724148  26015\n",
              "9244  0.119712  12970\n",
              "\n",
              "[9245 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "PLjy2DlMYMNp",
        "outputId": "5d112a90-9c39-4669-c165-74c7d9977926"
      },
      "source": [
        "pred_top2"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.472904</td>\n",
              "      <td>14061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.469834</td>\n",
              "      <td>16467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.534714</td>\n",
              "      <td>25725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.519413</td>\n",
              "      <td>9100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.515126</td>\n",
              "      <td>32597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9240</th>\n",
              "      <td>0.533943</td>\n",
              "      <td>31430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9241</th>\n",
              "      <td>0.504187</td>\n",
              "      <td>3876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9242</th>\n",
              "      <td>0.509907</td>\n",
              "      <td>20710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9243</th>\n",
              "      <td>0.513823</td>\n",
              "      <td>26015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9244</th>\n",
              "      <td>0.463586</td>\n",
              "      <td>12970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9245 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0     id\n",
              "0     0.472904  14061\n",
              "1     0.469834  16467\n",
              "2     0.534714  25725\n",
              "3     0.519413   9100\n",
              "4     0.515126  32597\n",
              "...        ...    ...\n",
              "9240  0.533943  31430\n",
              "9241  0.504187   3876\n",
              "9242  0.509907  20710\n",
              "9243  0.513823  26015\n",
              "9244  0.463586  12970\n",
              "\n",
              "[9245 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}